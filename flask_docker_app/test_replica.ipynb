{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae00451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "def load_tensor(path):\n",
    "    tensors = {}\n",
    "    try:\n",
    "        tensors[\"hidden_states\"] = torch.load(path + \"hidden_states.pt\").to(\"cuda:1\")\n",
    "        tensors[\"w1\"] = torch.load(path + \"w1.pt\").to(\"cuda:1\")\n",
    "        tensors[\"w2\"] = torch.load(path + \"w2.pt\").to(\"cuda:1\")\n",
    "        tensors[\"topk_weights\"] = torch.load(path + \"topk_weights.pt\").to(\"cuda:1\")\n",
    "        tensors[\"topk_ids\"] = torch.load(path + \"topk_ids.pt\").to(\"cuda:1\")\n",
    "        tensors[\"expert_map\"] = torch.load(path + \"expert_map.pt\").to(\"cuda:1\")\n",
    "        tensors[\"out_hidden_states\"] = torch.load(path + \"out_hidden_states.pt\").to(\"cuda:1\")\n",
    "        tensors[\"final_hidden_states\"] = torch.load(path + \"final_hidden_states.pt\").to(\"cuda:1\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: CUDA runtime issue - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    return tensors\n",
    "rank1 = load_tensor(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_1/\")\n",
    "rank0 = load_tensor(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_0/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004752cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print( torch.equal(rank1[\"hidden_states\"], rank0[\"hidden_states\"]) )\n",
    "print( torch.equal(rank1[\"topk_weights\"], rank0[\"topk_weights\"]) )\n",
    "print( torch.equal(rank1[\"topk_ids\"], rank0[\"topk_ids\"]) )\n",
    "print( torch.equal(rank1[\"final_hidden_states\"], rank0[\"final_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10b7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank0[\"shared_output\"] = torch.load(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_0/shared_output.pt\").to(\"cuda:1\")\n",
    "rank1[\"shared_output\"] = torch.load(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_1/shared_output.pt\").to(\"cuda:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cda88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1], device='cuda:1', dtype=torch.int32)\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,  3,  4,  5,\n",
      "         6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
      "        24, 25, 26, 27, 28, 29], device='cuda:1', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print( torch.equal(rank1[\"w1\"], rank0[\"w1\"]) )\n",
    "print( torch.equal(rank1[\"w2\"], rank0[\"w2\"]) )\n",
    "print( torch.equal(rank1[\"expert_map\"], rank0[\"expert_map\"]) )\n",
    "print( torch.equal(rank1[\"out_hidden_states\"], rank0[\"out_hidden_states\"]) )\n",
    "print( torch.equal(rank1[\"shared_output\"], rank0[\"shared_output\"]) )\n",
    "print(rank0[\"expert_map\"])\n",
    "print(rank1[\"expert_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b9900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27, 49, 41,  2],\n",
      "        [59,  3, 31, 41],\n",
      "        [24, 11, 52, 48],\n",
      "        [29, 53, 47, 13],\n",
      "        [13, 11, 52, 16],\n",
      "        [ 1, 11, 26, 17]], device='cuda:1', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank1[\"topk_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb58cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 2816, 2048])\n",
      "torch.Size([31, 2816, 2048])\n",
      "torch.Size([30, 2048, 1408])\n",
      "torch.Size([31, 2048, 1408])\n",
      "tensor([[27, 49, 41,  2],\n",
      "        [59,  3, 31, 41],\n",
      "        [24, 11, 52, 48],\n",
      "        [29, 53, 47, 13],\n",
      "        [13, 11, 52, 16],\n",
      "        [ 1, 11, 26, 17]], device='cuda:1', dtype=torch.int32)\n",
      "tensor([[27, 49, 41,  2],\n",
      "        [59, 60, 31, 41],\n",
      "        [24, 11, 52, 48],\n",
      "        [29, 53, 47, 13],\n",
      "        [13, 11, 52, 16],\n",
      "        [ 1, 11, 26, 17]], device='cuda:1', dtype=torch.int32)\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1], device='cuda:1')\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,  3,  4,  5,\n",
      "         6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
      "        24, 25, 26, 27, 28, 29, 30], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# replica expert 59 , add new expert id = 60\n",
    "# modify rank0 weight\n",
    "print(rank1[\"w1\"].shape) # torch.Size([30, 2816, 2048])\n",
    "new_tensor = rank1[\"w1\"][-1, :, :]\n",
    "new_tensor = new_tensor.to(rank1[\"w1\"].device)\n",
    "rank1[\"w1\"] = torch.cat((rank1[\"w1\"], new_tensor.unsqueeze(0)), dim=0)\n",
    "print(rank1[\"w1\"].shape) # torch.Size([31, 2816, 2048])\n",
    "\n",
    "print(rank1[\"w2\"].shape) # torch.Size([30, 2048, 1408])\n",
    "new_tensor = rank1[\"w2\"][-1, :, :]\n",
    "new_tensor = new_tensor.to(rank1[\"w2\"].device)\n",
    "rank1[\"w2\"] = torch.cat((rank1[\"w2\"], new_tensor.unsqueeze(0)), dim=0)\n",
    "print(rank1[\"w2\"].shape) # torch.Size([31, 2048, 1408])\n",
    "\n",
    "#  modify topk_ids, 59-->60\n",
    "print(rank1[\"topk_ids\"])\n",
    "rank0[\"topk_ids\"][1][1]= 60\n",
    "rank1[\"topk_ids\"][1][1] = 60\n",
    "print(rank1[\"topk_ids\"])\n",
    "# modify expert_map\n",
    "rank0[\"expert_map\"] = torch.cat((rank0[\"expert_map\"], torch.tensor([-1]).to(rank0[\"expert_map\"].device)))\n",
    "print(rank0[\"expert_map\"])\n",
    "rank1[\"expert_map\"] = torch.cat((rank1[\"expert_map\"], torch.tensor([30]).to(rank1[\"expert_map\"].device)))\n",
    "print(rank1[\"expert_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9b8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vllm_test_field/myvllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 15:42:35 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 15:42:36,573\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-08 15:42:37 [fused_moe.py:954] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/ubuntu/vllm_test_field/vllm/vllm/model_executor/layers/fused_moe/configs/E=30,N=1408,device_name=NVIDIA_A10G.json\n",
      "INFO 05-08 15:42:37 [fused_moe.py:1658] expert_ids.shape: torch.Size([59])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Triton Error [CUDA]: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfused_moe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfused_moe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fused_experts_impl \n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# forward of rank0 moe layer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rank0_output = \u001b[43mfused_experts_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhidden_states\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopk_weights\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopk_weights\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopk_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopk_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msilu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank0\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpert_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mglobal_num_experts\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m61\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(rank0_output.shape)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m( torch.equal(rank0_output , rank0[\u001b[33m\"\u001b[39m\u001b[33mout_hidden_states\u001b[39m\u001b[33m\"\u001b[39m]) )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/vllm/vllm/model_executor/layers/fused_moe/fused_moe.py:1659\u001b[39m, in \u001b[36mfused_experts_impl\u001b[39m\u001b[34m(hidden_states, w1, w2, topk_weights, topk_ids, inplace, activation, use_fp8_w8a8, use_int8_w8a16, use_int4_w4a16, global_num_experts, expert_map, w1_scale, w2_scale, w1_zp, w2_zp, a1_scale, a2_scale, block_shape)\u001b[39m\n\u001b[32m   1654\u001b[39m sorted_token_ids, expert_ids, num_tokens_post_padded = (\n\u001b[32m   1655\u001b[39m     moe_align_block_size(curr_topk_ids, config[\u001b[33m'\u001b[39m\u001b[33mBLOCK_SIZE_M\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1656\u001b[39m                          global_num_experts, expert_map))\n\u001b[32m   1658\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpert_ids.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpert_ids.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m \u001b[43minvoke_fused_moe_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqcurr_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mintermediate_cache1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m                        \u001b[49m\u001b[43ma1q_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mw1_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mw1_zp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcurr_topk_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcurr_topk_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m                        \u001b[49m\u001b[43msorted_token_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mexpert_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mnum_tokens_post_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mtop_k_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m                        \u001b[49m\u001b[43muse_fp8_w8a8\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fp8_w8a8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m                        \u001b[49m\u001b[43muse_int8_w8a16\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_int8_w8a16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m                        \u001b[49m\u001b[43muse_int4_w4a16\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_int4_w4a16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m activation == \u001b[33m\"\u001b[39m\u001b[33msilu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1680\u001b[39m     torch.ops._C.silu_and_mul(intermediate_cache2,\n\u001b[32m   1681\u001b[39m                               intermediate_cache1.view(-\u001b[32m1\u001b[39m, N))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/vllm/vllm/model_executor/layers/fused_moe/fused_moe.py:865\u001b[39m, in \u001b[36minvoke_fused_moe_kernel\u001b[39m\u001b[34m(A, B, C, A_scale, B_scale, B_zp, topk_weights, topk_ids, sorted_token_ids, expert_ids, num_tokens_post_padded, mul_routed_weight, top_k, config, compute_type, use_fp8_w8a8, use_int8_w8a16, use_int4_w4a16, block_shape)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    863\u001b[39m     BLOCK_SIZE_K = \u001b[38;5;28mmin\u001b[39m(BLOCK_SIZE_K, \u001b[38;5;28mmin\u001b[39m(block_shape[\u001b[32m0\u001b[39m],\n\u001b[32m    864\u001b[39m                                          block_shape[\u001b[32m1\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m \u001b[43mfused_moe_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopk_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43msorted_token_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_tokens_post_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopk_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mA_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mB_scale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMUL_ROUTED_WEIGHT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmul_routed_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_fp8_w8a8\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fp8_w8a8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_int8_w8a16\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_int8_w8a16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBLOCK_SIZE_K\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBLOCK_SIZE_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/myvllm/lib/python3.12/site-packages/triton/runtime/jit.py:330\u001b[39m, in \u001b[36mKernelInterface.__getitem__.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid) -> T:\n\u001b[32m    325\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    A JIT function is launched with: fn[grid](*args, **kwargs).\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    Hence JITFunction.__getitem__ returns a callable proxy that\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m    memorizes the grid.\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/myvllm/lib/python3.12/site-packages/triton/runtime/jit.py:653\u001b[39m, in \u001b[36mJITFunction.run\u001b[39m\u001b[34m(self, grid, warmup, *args, **kwargs)\u001b[39m\n\u001b[32m    651\u001b[39m     \u001b[38;5;66;03m# launch kernel\u001b[39;00m\n\u001b[32m    652\u001b[39m     launch_metadata = kernel.launch_metadata(grid, stream, *non_constexpr_vals)\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[43mkernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m(grid_0, grid_1, grid_2, stream, kernel.function, kernel.packed_metadata, launch_metadata,\n\u001b[32m    654\u001b[39m                \u001b[38;5;28mself\u001b[39m.CompiledKernel.launch_enter_hook, \u001b[38;5;28mself\u001b[39m.CompiledKernel.launch_exit_hook, *non_constexpr_vals)\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m kernel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/myvllm/lib/python3.12/site-packages/triton/compiler/compiler.py:395\u001b[39m, in \u001b[36mCompiledKernel.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m'\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vllm_test_field/myvllm/lib/python3.12/site-packages/triton/compiler/compiler.py:390\u001b[39m, in \u001b[36mCompiledKernel._init_handles\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutOfResources(\u001b[38;5;28mself\u001b[39m.metadata.shared, max_shared, \u001b[33m\"\u001b[39m\u001b[33mshared memory\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# TODO: n_regs, n_spills should be metadata generated when calling `ptxas`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m \u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.function, \u001b[38;5;28mself\u001b[39m.n_regs, \u001b[38;5;28mself\u001b[39m.n_spills = \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_binary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Triton Error [CUDA]: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "from vllm.model_executor.layers.fused_moe.fused_moe import fused_experts_impl \n",
    "# forward of rank0 moe layer\n",
    "rank0_output = fused_experts_impl(\n",
    "    hidden_states = rank0[\"hidden_states\"],\n",
    "    w1 = rank0[\"w1\"],\n",
    "    w2 = rank0[\"w2\"],\n",
    "    topk_weights = rank0[\"topk_weights\"],\n",
    "    topk_ids = rank0[\"topk_ids\"],\n",
    "    inplace = True,\n",
    "    activation = \"silu\",\n",
    "    expert_map = rank0[\"expert_map\"],\n",
    "    global_num_experts = 61 \n",
    ")\n",
    "print(rank0_output.shape)\n",
    "print( torch.equal(rank0_output , rank0[\"out_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80318e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-08 15:26:59 [fused_moe.py:954] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/ubuntu/vllm_test_field/vllm/vllm/model_executor/layers/fused_moe/configs/E=31,N=1408,device_name=NVIDIA_A10G.json\n",
      "INFO 05-08 15:26:59 [fused_moe.py:1658] expert_ids.shape: torch.Size([59])\n",
      "torch.Size([6, 2048])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# forward of rank1 moe layer\n",
    "rank1_output = fused_experts_impl(\n",
    "    hidden_states = rank1[\"hidden_states\"],\n",
    "    w1 = rank1[\"w1\"],\n",
    "    w2 = rank1[\"w2\"],\n",
    "    topk_weights = rank1[\"topk_weights\"],\n",
    "    topk_ids = rank1[\"topk_ids\"],\n",
    "    inplace = True,\n",
    "    activation = \"silu\",\n",
    "    expert_map = rank1[\"expert_map\"],\n",
    "    global_num_experts = 61\n",
    ")\n",
    "print(rank1_output.shape)\n",
    "print( torch.equal(rank1_output , rank1[\"out_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c47703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "rank0_final_hidden_states = rank0_output + rank0[\"shared_output\"]\n",
    "rank1_final_hidden_states = rank1_output + rank1[\"shared_output\"]\n",
    "# all reduce \n",
    "reduced_result = rank0_final_hidden_states + rank1_final_hidden_states\n",
    "print( torch.equal(reduced_result, \n",
    "                   rank0[\"final_hidden_states\"]) )\n",
    "\n",
    "print( torch.equal(reduced_result, \n",
    "                   rank1[\"final_hidden_states\"]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
