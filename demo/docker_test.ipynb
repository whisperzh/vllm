{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbe2b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 (NVIDIA A10G):\n",
      "  Total Memory: 21.99 GB\n",
      "  Used Memory: 0.00 GB\n",
      "  Available Memory: 21.99 GB\n",
      "GPU 1 (NVIDIA A10G):\n",
      "  Total Memory: 21.99 GB\n",
      "  Used Memory: 0.00 GB\n",
      "  Available Memory: 21.99 GB\n",
      "GPU 2 (NVIDIA A10G):\n",
      "  Total Memory: 21.99 GB\n",
      "  Used Memory: 0.00 GB\n",
      "  Available Memory: 21.99 GB\n",
      "GPU 3 (NVIDIA A10G):\n",
      "  Total Memory: 21.99 GB\n",
      "  Used Memory: 0.00 GB\n",
      "  Available Memory: 21.99 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_gpu_memory_simple():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No available CUDA GPU\")\n",
    "        return\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        total = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)  # GB\n",
    "        allocated = torch.cuda.memory_allocated(i) / (1024 ** 3)  # GB\n",
    "        free = (torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_reserved(i)) / (1024 ** 3)  # GB\n",
    "        \n",
    "        print(f\"GPU {i} ({name}):\")\n",
    "        print(f\"  Total Memory: {total:.2f} GB\")\n",
    "        print(f\"  Used Memory: {allocated:.2f} GB\")\n",
    "        print(f\"  Available Memory: {free:.2f} GB\")\n",
    "\n",
    "check_gpu_memory_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f959d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddd5d5",
   "metadata": {},
   "source": [
    "## Launch the fused moe as a flask server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34c9ec",
   "metadata": {},
   "source": [
    "## Define an api that receive hidden layer data and return the processed result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4289f9",
   "metadata": {},
   "source": [
    "## Load all weights using the given instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e673b",
   "metadata": {},
   "source": [
    "## naive implementation（using Bei's code）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6964b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(path):\n",
    "    tensors = {}\n",
    "    try:\n",
    "        tensors[\"hidden_states\"] = torch.load(path + \"hidden_states.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"w1\"] = torch.load(path + \"w1.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"w2\"] = torch.load(path + \"w2.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"topk_weights\"] = torch.load(path + \"topk_weights.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"topk_ids\"] = torch.load(path + \"topk_ids.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"expert_map\"] = torch.load(path + \"expert_map.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"out_hidden_states\"] = torch.load(path + \"out_hidden_states.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "        tensors[\"final_hidden_states\"] = torch.load(path + \"final_hidden_states.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: CUDA runtime issue - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    return tensors\n",
    "rank1 = load_tensor(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_1/\")\n",
    "rank0 = load_tensor(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_0/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc490e0",
   "metadata": {},
   "source": [
    "### load shared experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab7707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank0[\"shared_output\"] = torch.load(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_0/shared_output.pt\",map_location=\"cuda:0\").to(\"cuda\")\n",
    "rank1[\"shared_output\"] = torch.load(\"/home/ubuntu/vllm_test_field/saved_tensors/rank_1/shared_output.pt\",map_location=\"cuda:0\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899ddc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hidden_states', 'w1', 'w2', 'topk_weights', 'topk_ids', 'expert_map', 'out_hidden_states', 'final_hidden_states', 'shared_output'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank0.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f616b8",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84894c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2816, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank1[\"w1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54869579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1], device='cuda:0', dtype=torch.int32)\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,  3,  4,  5,\n",
      "         6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
      "        24, 25, 26, 27, 28, 29], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print( torch.equal(rank1[\"w1\"], rank0[\"w1\"]) )\n",
    "print( torch.equal(rank1[\"w2\"], rank0[\"w2\"]) )\n",
    "print( torch.equal(rank1[\"expert_map\"], rank0[\"expert_map\"]) )\n",
    "print( torch.equal(rank1[\"out_hidden_states\"], rank0[\"out_hidden_states\"]) )\n",
    "print( torch.equal(rank1[\"shared_output\"], rank0[\"shared_output\"]) )\n",
    "print(rank0[\"expert_map\"])\n",
    "print(rank1[\"expert_map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d043718",
   "metadata": {},
   "source": [
    "### run rank 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa87765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27, 49, 41,  2],\n",
       "         [59,  3, 31, 41],\n",
       "         [24, 11, 52, 48],\n",
       "         [29, 53, 47, 13],\n",
       "         [13, 11, 52, 16],\n",
       "         [ 1, 11, 26, 17]], device='cuda:0', dtype=torch.int32),\n",
       " tensor([[27, 49, 41,  2],\n",
       "         [59,  3, 31, 41],\n",
       "         [24, 11, 52, 48],\n",
       "         [29, 53, 47, 13],\n",
       "         [13, 11, 52, 16],\n",
       "         [ 1, 11, 26, 17]], device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank0[\"topk_ids\"], rank1[\"topk_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vllm_test_field/myvllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-06 07:28:20 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 07:28:21,720\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-06 07:28:22 [fused_moe.py:954] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/ubuntu/vllm_test_field/vllm/vllm/model_executor/layers/fused_moe/configs/E=30,N=1408,device_name=NVIDIA_A10G.json\n",
      "INFO 05-06 07:28:22 [fused_moe.py:1658] expert_ids.shape: torch.Size([58])\n",
      "torch.Size([6, 2048])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from vllm.model_executor.layers.fused_moe.fused_moe import fused_experts_impl \n",
    "# forward of rank0 moe layer\n",
    "rank0_output = fused_experts_impl(\n",
    "    hidden_states = rank0[\"hidden_states\"],\n",
    "    w1 = rank0[\"w1\"],\n",
    "    w2 = rank0[\"w2\"],\n",
    "    topk_weights = rank0[\"topk_weights\"],\n",
    "    topk_ids = rank0[\"topk_ids\"],\n",
    "    inplace = True,\n",
    "    activation = \"silu\",\n",
    "    expert_map = rank0[\"expert_map\"],\n",
    "    global_num_experts = 60 \n",
    ")\n",
    "print(rank0_output.shape)\n",
    "print( torch.equal(rank0_output , rank0[\"out_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d6851",
   "metadata": {},
   "source": [
    "### run rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d97182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-06 07:28:26 [fused_moe.py:1658] expert_ids.shape: torch.Size([58])\n",
      "torch.Size([6, 2048])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# forward of rank1 moe layer\n",
    "rank1_output = fused_experts_impl(\n",
    "    hidden_states = rank1[\"hidden_states\"],\n",
    "    w1 = rank1[\"w1\"],\n",
    "    w2 = rank1[\"w2\"],\n",
    "    topk_weights = rank1[\"topk_weights\"],\n",
    "    topk_ids = rank1[\"topk_ids\"],\n",
    "    inplace = True,\n",
    "    activation = \"silu\",\n",
    "    expert_map = rank1[\"expert_map\"],\n",
    "    global_num_experts = 60\n",
    ")\n",
    "print(rank1_output.shape)\n",
    "print( torch.equal(rank1_output , rank1[\"out_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890b92f",
   "metadata": {},
   "source": [
    "### merge and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rank0_final_hidden_states = rank0_output + rank0[\"shared_output\"]\n",
    "rank1_final_hidden_states = rank1_output + rank1[\"shared_output\"]\n",
    "# all reduce \n",
    "reduced_result = rank0_final_hidden_states + rank1_final_hidden_states\n",
    "print( torch.equal(reduced_result, \n",
    "                   rank0[\"final_hidden_states\"]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b3000",
   "metadata": {},
   "source": [
    "## Try loading weights using IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e06a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/vllm_test_field/myvllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaConfig, AutoTokenizer\n",
    "import torch\n",
    "import ctypes\n",
    "import os, time, json, sys\n",
    "import cupy as cp\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f464fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_tensor_info():\n",
    "    current_dir = os.getcwd()\n",
    "    tensor_info_path = os.path.join(current_dir, \"tensor_info.json\")\n",
    "    with open(tensor_info_path, 'r') as f:\n",
    "        tensor_info_raw = json.load(f)\n",
    "    \n",
    "    # 转换数据类型\n",
    "    tensor_info = {}\n",
    "    for key, info in tensor_info_raw.items():\n",
    "        tensor_info[key] = {\n",
    "            'size': tuple(info['size']),  # 转换回tuple\n",
    "            'dtype': getattr(torch, info['dtype'].split('.')[-1]),  # 转换回torch.dtype\n",
    "            'numel': info['numel']\n",
    "        }\n",
    "    \n",
    "    return tensor_info\n",
    "\n",
    "\n",
    "# 获取当前脚本所在目录\n",
    "current_dir = os.getcwd()\n",
    "# 拼接绝对路径\n",
    "lib_path = os.path.join(current_dir, \"ipc_handle.so\")\n",
    "# 加载共享库\n",
    "lib = ctypes.CDLL(lib_path)\n",
    "#lib = ctypes.CDLL(\"./libipc_handle.so\")\n",
    "\n",
    "# Define the function types\n",
    "lib.open_ipc_handle.restype = ctypes.c_void_p\n",
    "lib.open_ipc_handle.argtypes = [ctypes.c_char_p]\n",
    "\n",
    "# 初始化一个空的state_dict，只包含key信息\n",
    "tensor_info = load_tensor_info()\n",
    "state_dict = {key: None for key in tensor_info.keys()}\n",
    "\n",
    "handle_directory = \"/home/ubuntu/vllm_test_field/vllm/demo/handles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c36a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqqq=filter(lambda x: \"att\" not in x, list(state_dict.keys()))\n",
    "qqqq = sorted(list(qqqq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f351fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict={}\n",
    "def load_model_shard_by_key(key,state_dict):\n",
    "    handle_file = f\"{handle_directory}/device_0/{key.replace('.', '_')}.bin.ipc\"\n",
    "    if not os.path.exists(handle_file):\n",
    "        print(f\"The specified IPC file does not exist: {handle_file}\")\n",
    "        return\n",
    "\n",
    "    device_ptr = lib.open_ipc_handle(handle_file.encode('utf-8'))\n",
    "    if device_ptr:\n",
    "        tensor_size = tensor_info[key]['numel']\n",
    "        dtype_map = {\n",
    "            torch.float32: cp.float32,\n",
    "            torch.float64: cp.float64,\n",
    "            torch.int32: cp.int32,\n",
    "            torch.int64: cp.int64,\n",
    "            torch.uint8: cp.uint8,\n",
    "            torch.int8: cp.int8,\n",
    "            torch.int16: cp.int16,\n",
    "            torch.float16: cp.float16\n",
    "        }\n",
    "        # 使用提前知道的dtype信息\n",
    "        cp_dtype = dtype_map.get(tensor_info[key]['dtype'])\n",
    "\n",
    "        # Wrap the raw GPU pointer using CuPy\n",
    "        gpu_array = cp.ndarray((tensor_size,), dtype=cp_dtype, memptr=cp.cuda.MemoryPointer(cp.cuda.UnownedMemory(\n",
    "            device_ptr, tensor_size * cp_dtype().itemsize, None), 0))\n",
    "        \n",
    "        # Convert CuPy array to PyTorch tensor using DLPack\n",
    "        try:\n",
    "            dlpack = gpu_array.toDlpack()\n",
    "            #state_dict[key] = torch.utils.dlpack.from_dlpack(dlpack).view(tensor_info[key]['size'])\n",
    "            \n",
    "            torch_tensor = torch.utils.dlpack.from_dlpack(dlpack)\n",
    "            state_dict[key] = torch_tensor.view(tensor_info[key]['size'])\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error with key {key}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to open IPC handle for {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91317a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-07 03:34:32 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 03:34:33,353\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-07 03:34:34 [config.py:3781] Current vLLM config is not set.\n",
      "WARNING 05-07 03:34:34 [config.py:3781] Current vLLM config is not set.\n",
      "WARNING 05-07 03:34:34 [config.py:3781] Current vLLM config is not set.\n",
      "WARNING 05-07 03:34:34 [config.py:3781] Current vLLM config is not set.\n"
     ]
    }
   ],
   "source": [
    "from vllm.model_executor.layers.fused_moe import FusedMoE\n",
    "import transformers\n",
    "\n",
    "    # 加载配置\n",
    "config = transformers.AutoConfig.from_pretrained(\"Qwen/Qwen1.5-MoE-A2.7B\")\n",
    "experts = FusedMoE(num_experts=config.num_experts,\n",
    "                        top_k=config.num_experts_per_tok,\n",
    "                        hidden_size=config.hidden_size,\n",
    "                        intermediate_size=config.moe_intermediate_size,\n",
    "                        reduce_results=False,\n",
    "                        renormalize=config.norm_topk_prob,\n",
    "                        tp_size=1,\n",
    "                        dp_size=1)\n",
    "\n",
    "expert_params_mapping = FusedMoE.make_expert_params_mapping(\n",
    "            ckpt_gate_proj_name=\"gate_proj\",\n",
    "            ckpt_down_proj_name=\"down_proj\",\n",
    "            ckpt_up_proj_name=\"up_proj\",\n",
    "            num_experts=config.num_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55344753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to open IPC handle: invalid resource handle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to open IPC handle for model.layers.23.mlp.experts.16.down_proj.weight\n"
     ]
    }
   ],
   "source": [
    "state_dict_keys=[\"model.layers.23.mlp.experts.16.down_proj.weight\",\n",
    "                 ]\n",
    "state_dict={}\n",
    "for k in state_dict_keys:\n",
    "   load_model_shard_by_key(k,state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ee4421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['w13_weight', 'w2_weight'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict=dict(experts.named_parameters())\n",
    "print(params_dict.keys())\n",
    "name=\"\"\n",
    "shard_id=\"w2\"\n",
    "expert_id=0\n",
    "experts.weight_loader(params_dict[\"w2_weight\"],,name,shard_id,expert_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218e2082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experts.w13_', 'experts.59.gate_proj.', 59, 'w1'),\n",
       " ('experts.w2_', 'experts.59.down_proj.', 59, 'w2'),\n",
       " ('experts.w13_', 'experts.59.up_proj.', 59, 'w3')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_params_mapping[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f8931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.layers.0.mlp.experts.w13_weight',\n",
       " 'model.layers.0.mlp.experts.w2_weight',\n",
       " 'model.layers.1.mlp.experts.w13_weight',\n",
       " 'model.layers.1.mlp.experts.w2_weight',\n",
       " 'model.layers.2.mlp.experts.w13_weight',\n",
       " 'model.layers.2.mlp.experts.w2_weight',\n",
       " 'model.layers.3.mlp.experts.w13_weight',\n",
       " 'model.layers.3.mlp.experts.w2_weight',\n",
       " 'model.layers.4.mlp.experts.w13_weight',\n",
       " 'model.layers.4.mlp.experts.w2_weight',\n",
       " 'model.layers.5.mlp.experts.w13_weight',\n",
       " 'model.layers.5.mlp.experts.w2_weight',\n",
       " 'model.layers.6.mlp.experts.w13_weight',\n",
       " 'model.layers.6.mlp.experts.w2_weight',\n",
       " 'model.layers.7.mlp.experts.w13_weight',\n",
       " 'model.layers.7.mlp.experts.w2_weight',\n",
       " 'model.layers.8.mlp.experts.w13_weight',\n",
       " 'model.layers.8.mlp.experts.w2_weight',\n",
       " 'model.layers.9.mlp.experts.w13_weight',\n",
       " 'model.layers.9.mlp.experts.w2_weight',\n",
       " 'model.layers.10.mlp.experts.w13_weight',\n",
       " 'model.layers.10.mlp.experts.w2_weight',\n",
       " 'model.layers.11.mlp.experts.w13_weight',\n",
       " 'model.layers.11.mlp.experts.w2_weight',\n",
       " 'model.layers.12.mlp.experts.w13_weight',\n",
       " 'model.layers.12.mlp.experts.w2_weight',\n",
       " 'model.layers.13.mlp.experts.w13_weight',\n",
       " 'model.layers.13.mlp.experts.w2_weight',\n",
       " 'model.layers.14.mlp.experts.w13_weight',\n",
       " 'model.layers.14.mlp.experts.w2_weight',\n",
       " 'model.layers.15.mlp.experts.w13_weight',\n",
       " 'model.layers.15.mlp.experts.w2_weight',\n",
       " 'model.layers.16.mlp.experts.w13_weight',\n",
       " 'model.layers.16.mlp.experts.w2_weight',\n",
       " 'model.layers.17.mlp.experts.w13_weight',\n",
       " 'model.layers.17.mlp.experts.w2_weight',\n",
       " 'model.layers.18.mlp.experts.w13_weight',\n",
       " 'model.layers.18.mlp.experts.w2_weight',\n",
       " 'model.layers.19.mlp.experts.w13_weight',\n",
       " 'model.layers.19.mlp.experts.w2_weight',\n",
       " 'model.layers.20.mlp.experts.w13_weight',\n",
       " 'model.layers.20.mlp.experts.w2_weight',\n",
       " 'model.layers.21.mlp.experts.w13_weight',\n",
       " 'model.layers.21.mlp.experts.w2_weight',\n",
       " 'model.layers.22.mlp.experts.w13_weight',\n",
       " 'model.layers.22.mlp.experts.w2_weight',\n",
       " 'model.layers.23.mlp.experts.w13_weight',\n",
       " 'model.layers.23.mlp.experts.w2_weight']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open (\"qwen2moeparams_dict.pkl\", \"rb\") as f:\n",
    "    params_dict = pickle.load(f)\n",
    "    \n",
    "params_dict=[i for i in params_dict if \"mlp.experts\" in i] \n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.model_executor.models.utils import (extract_layer_index, is_pp_missing_parameter,\n",
    "                    make_empty_intermediate_tensors_factory, make_layers,\n",
    "                    maybe_prefix)\n",
    "from typing import Any, Dict, Iterable, Optional, Set, Tuple, Union\n",
    "\n",
    "experts.weight_loader(param,\n",
    "                    loaded_weight,\n",
    "                    name,\n",
    "                    shard_id=shard_id,\n",
    "                    expert_id=expert_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open (\"qwen2moeparams_dict.pkl\", \"r\") as f:\n",
    "    params_dict = json.load(f)\n",
    "    \n",
    "for mapping in expert_params_mapping:\n",
    "    param_name, weight_name, expert_id, shard_id = mapping\n",
    "    if weight_name not in name:\n",
    "        continue\n",
    "    name = name.replace(weight_name, param_name)\n",
    "    # Skip loading extra bias for GPTQ models.\n",
    "    # if is_pp_missing_parameter(name, self):\n",
    "    #                     continue\n",
    "                    # Skip loading extra bias for GPTQ models.\n",
    "    if ((name.endswith(\".bias\") or name.endswith(\"_bias\"))\n",
    "            and name not in params_dict):\n",
    "        continue\n",
    "    param = params_dict[name]\n",
    "    weight_loader = param.weight_loader\n",
    "    weight_loader(param,\n",
    "                    loaded_weight,\n",
    "                    name,\n",
    "                    shard_id=shard_id,\n",
    "                    expert_id=expert_id)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b1781",
   "metadata": {},
   "source": [
    "## Try Load Weights just using pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c546d83",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
