{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02f8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ctypes\n",
    "\n",
    "# Load shared library\n",
    "lib = ctypes.CDLL('./cuda_tools/libipc_tensor_tool.so')\n",
    "lib.open_ipc_tensor.argtypes = [ctypes.c_void_p, ctypes.c_int]\n",
    "lib.open_ipc_tensor.restype = ctypes.c_void_p\n",
    "\n",
    "lib.close_ipc_tensor.argtypes = [ctypes.c_void_p]\n",
    "lib.close_ipc_tensor.restype = ctypes.c_int\n",
    "\n",
    "\n",
    "DTYPE_SIZE = {\n",
    "    torch.float32: 4,\n",
    "    torch.int32: 4,\n",
    "    torch.int64: 8,\n",
    "    torch.float64: 8,\n",
    "    torch.uint8: 1,\n",
    "    torch.bfloat16: 2,\n",
    "    # add more if needed\n",
    "}\n",
    "\n",
    "DTYPE_MAP = {\n",
    "    'torch.float32':torch.float32,\n",
    "    'torch.int32':torch.int32,\n",
    "    'torch.int64':torch.int64,\n",
    "    'torch.float64':torch.float64,\n",
    "    'torch.uint8':torch.uint8,\n",
    "    'torch.float16':torch.float16,\n",
    "    'torch.bfloat16':torch.bfloat16,\n",
    "}\n",
    "\n",
    "def restore_tensor(ipc_handle_bytes: bytes, meta):\n",
    "    shape = meta['shape']\n",
    "    dtype = meta['dtype']\n",
    "    device = meta['device']\n",
    "    \n",
    "    if len(ipc_handle_bytes) != 64:\n",
    "        raise ValueError(\"Invalid IPC handle size\")\n",
    "\n",
    "    dtype = DTYPE_MAP.get(dtype, None)\n",
    "    if dtype not in DTYPE_SIZE:\n",
    "        raise ValueError(f\"Unsupported dtype: {dtype}\")\n",
    "\n",
    "    handle_buf = ctypes.create_string_buffer(ipc_handle_bytes, 64)\n",
    "    dev_ptr = lib.open_ipc_tensor(handle_buf, device)\n",
    "\n",
    "    if not dev_ptr:\n",
    "        raise RuntimeError(\"Failed to open IPC handle\")\n",
    "\n",
    "    numel = torch.prod(torch.tensor(shape)).item()\n",
    "    nbytes = numel * DTYPE_SIZE[dtype]\n",
    "\n",
    "    # Wrap the pointer as a ctypes pointer of the right type\n",
    "    # (important: we cast to ctypes type matching dtype)\n",
    "    ptr_type = ctypes.POINTER(ctypes.c_float)  # default\n",
    "    if dtype == torch.float32:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_float)\n",
    "    elif dtype == torch.int32:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_int32)\n",
    "    elif dtype == torch.int64:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_int64)\n",
    "    elif dtype == torch.float64:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_double)\n",
    "    elif dtype == torch.uint8:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_uint8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dtype for ctypes cast: {dtype}\")\n",
    "\n",
    "    typed_ptr = ctypes.cast(dev_ptr, ptr_type)\n",
    "\n",
    "    # Use torch.from_blob (no ownership)\n",
    "    t = torch.frombuffer(\n",
    "        (ctypes.c_char * nbytes).from_address(dev_ptr),\n",
    "        dtype=dtype\n",
    "    ).view(*shape).to(f'cuda:{device}')\n",
    "    lib.close_ipc_tensor(dev_ptr)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fc581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import torch\n",
    "import ctypes\n",
    "\n",
    "lib = ctypes.CDLL('/root/vllm_test/vllm/ipc_handler_demo/ipc_handle.so')\n",
    "lib.open_ipc_handle.argtypes = [ctypes.c_void_p]\n",
    "# Define the function types\n",
    "lib.open_ipc_handle.restype = ctypes.c_void_p\n",
    "\n",
    "\n",
    "def xuezhang_de_fangfa(handler_bytes, meta):\n",
    "    torch.cuda.set_device(0)\n",
    "    device_ptr = lib.open_ipc_handle(handler_bytes)\n",
    "    if device_ptr:\n",
    "        tensor_size = meta['numel']\n",
    "        dtype_map = {\n",
    "            'torch.float32': cp.float32,\n",
    "            'torch.float64': cp.float64,\n",
    "            'torch.int32': cp.int32,\n",
    "            'torch.int64': cp.int64,\n",
    "            'torch.uint8': cp.uint8,\n",
    "            'torch.int8': cp.int8,\n",
    "            'torch.int16': cp.int16,\n",
    "            'torch.float16': cp.float16,\n",
    "            'torch.bfloat16': cp.float16  # Map bfloat16 to float16 since CuPy doesn't support bfloat16\n",
    "        }\n",
    "        # 使用提前知道的dtype信息\n",
    "        cp_dtype = dtype_map.get(meta['dtype'])\n",
    "        if cp_dtype is None:\n",
    "            raise ValueError(f\"Unsupported dtype: {meta['dtype']}\")\n",
    "\n",
    "        unownedmemory = cp.cuda.UnownedMemory(\n",
    "            device_ptr, tensor_size * cp_dtype().itemsize, None)\n",
    "        # Wrap the raw GPU pointer using CuPy\n",
    "        gpu_array = cp.ndarray((tensor_size,), dtype=cp_dtype, memptr=cp.cuda.MemoryPointer(unownedmemory, 0))\n",
    "\n",
    "        # Convert CuPy array to PyTorch tensor using DLPack\n",
    "        dlpack = gpu_array.toDlpack()\n",
    "        restored = torch.utils.dlpack.from_dlpack(dlpack).view(meta['shape'])\n",
    "        \n",
    "        # If original dtype was bfloat16, convert back to bfloat16\n",
    "        if meta['dtype'] == 'torch.bfloat16':\n",
    "            restored = restored.to(torch.bfloat16)\n",
    "            \n",
    "        return restored\n",
    "    else:\n",
    "        print(f\"Failed to open IPC handle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 1177 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/vllm_test/myllm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "from flask import Flask, request, jsonify, Response\n",
    "import json\n",
    "from tensor_utils import restore_tensor_torch\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload():\n",
    "    # 1. 获取二进制数据（如文件）\n",
    "    byte_data = request.files['byte_data'].read()\n",
    "    \n",
    "    # 2. 获取字典数据（JSON 格式）\n",
    "    map_data = json.loads(request.form['map_data']) \n",
    "    \n",
    "    t = restore_tensor(byte_data, map_data)\n",
    "    # t = load_model_shard_by_key(byte_data, map_data)\n",
    "    # t = restore_tensor(byte_data, shape=map_data[\"shape\"], dtype=map_data[\"dtype\"], device=int(map_data[\"device\"]))\n",
    "    print(t)\n",
    "    # 3. 返回结果\n",
    "    response = {\n",
    "        'message':\"ok\",\n",
    "        'restored_tensor':t.cpu().tolist(),  # Convert to list for JSON serialization\n",
    "    }\n",
    "    \n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=1177)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
