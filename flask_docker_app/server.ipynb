{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02f8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ctypes\n",
    "\n",
    "# Load shared library\n",
    "lib = ctypes.CDLL('./cuda_tools/libipc_tensor_tool.so')\n",
    "lib.open_ipc_tensor.argtypes = [ctypes.c_void_p, ctypes.c_int]\n",
    "lib.open_ipc_tensor.restype = ctypes.c_void_p\n",
    "\n",
    "lib.close_ipc_tensor.argtypes = [ctypes.c_void_p]\n",
    "lib.close_ipc_tensor.restype = ctypes.c_int\n",
    "\n",
    "\n",
    "DTYPE_SIZE = {\n",
    "    torch.float32: 4,\n",
    "    torch.int32: 4,\n",
    "    torch.int64: 8,\n",
    "    torch.float64: 8,\n",
    "    torch.uint8: 1,\n",
    "    # add more if needed\n",
    "}\n",
    "\n",
    "DTYPE_MAP = {\n",
    "    'torch.float32':torch.float32,\n",
    "    'torch.int32':torch.int32,\n",
    "    'torch.int64':torch.int64,\n",
    "    'torch.float64':torch.float64,\n",
    "    'torch.uint8':torch.uint8,\n",
    "    'torch.float16':torch.float16,\n",
    "    'torch.bfloat16':torch.bfloat16,\n",
    "}\n",
    "\n",
    "def restore_tensor(ipc_handle_bytes: bytes, shape, dtype=torch.float32, device=0):\n",
    "    if len(ipc_handle_bytes) != 64:\n",
    "        raise ValueError(\"Invalid IPC handle size\")\n",
    "\n",
    "    dtype = DTYPE_MAP.get(dtype, None)\n",
    "    if dtype not in DTYPE_SIZE:\n",
    "        raise ValueError(f\"Unsupported dtype: {dtype}\")\n",
    "\n",
    "    handle_buf = ctypes.create_string_buffer(ipc_handle_bytes, 64)\n",
    "    dev_ptr = lib.open_ipc_tensor(handle_buf, device)\n",
    "\n",
    "    if not dev_ptr:\n",
    "        raise RuntimeError(\"Failed to open IPC handle\")\n",
    "\n",
    "    numel = torch.prod(torch.tensor(shape)).item()\n",
    "    nbytes = numel * DTYPE_SIZE[dtype]\n",
    "\n",
    "    # Wrap the pointer as a ctypes pointer of the right type\n",
    "    # (important: we cast to ctypes type matching dtype)\n",
    "    ptr_type = ctypes.POINTER(ctypes.c_float)  # default\n",
    "    if dtype == torch.float32:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_float)\n",
    "    elif dtype == torch.int32:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_int32)\n",
    "    elif dtype == torch.int64:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_int64)\n",
    "    elif dtype == torch.float64:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_double)\n",
    "    elif dtype == torch.uint8:\n",
    "        ptr_type = ctypes.POINTER(ctypes.c_uint8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dtype for ctypes cast: {dtype}\")\n",
    "\n",
    "    typed_ptr = ctypes.cast(dev_ptr, ptr_type)\n",
    "\n",
    "    # Use torch.from_blob (no ownership)\n",
    "    t = torch.frombuffer(\n",
    "        (ctypes.c_char * nbytes).from_address(dev_ptr),\n",
    "        dtype=dtype\n",
    "    ).view(*shape).to(f'cuda:{device}')\n",
    "    lib.close_ipc_tensor(dev_ptr)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:1177\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-14 02:41:30,191] ERROR in app: Exception on /upload [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/vllm_test/myllm/lib/python3.10/site-packages/flask/app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/root/vllm_test/myllm/lib/python3.10/site-packages/flask/app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/root/vllm_test/myllm/lib/python3.10/site-packages/flask/app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/root/vllm_test/myllm/lib/python3.10/site-packages/flask/app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "  File \"/tmp/ipykernel_14957/2766625509.py\", line 14, in upload\n",
      "    t = restore_tensor(byte_data, shape=map_data[\"shape\"], dtype=getattr(torch, map_data[\"dtype\"]), device=int(map_data[\"device\"]))\n",
      "  File \"/root/vllm_test/myllm/lib/python3.10/site-packages/torch/__init__.py\", line 2681, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute 'torch.float32'\n",
      "127.0.0.1 - - [14/May/2025 02:41:30] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, Response\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload():\n",
    "    # 1. 获取二进制数据（如文件）\n",
    "    byte_data = request.files['byte_data'].read()\n",
    "    \n",
    "    # 2. 获取字典数据（JSON 格式）\n",
    "    map_data = json.loads(request.form['map_data']) \n",
    "    \n",
    "    t = restore_tensor(byte_data, shape=map_data[\"shape\"], dtype=map_data[\"dtype\"], device=int(map_data[\"device\"]))\n",
    "    print(t)\n",
    "    # 3. 返回结果\n",
    "    response = {\n",
    "        'message':\"ok\",\n",
    "        'restored_tensor':t.cpu().tolist(),  # Convert to list for JSON serialization\n",
    "    }\n",
    "    \n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=1177)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
