{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02fb600",
   "metadata": {},
   "source": [
    "## Test if my GPU supports P2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f41de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 GPU(s)\n",
      "GPU 0 can access GPU 1 via P2P: ❌ No\n",
      "GPU 1 can access GPU 0 via P2P: ❌ No\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_p2p_support():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA is not available. No GPUs detected.\")\n",
    "        return\n",
    "\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Found {num_gpus} GPU(s)\")\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        for j in range(num_gpus):\n",
    "            if i == j:\n",
    "                continue  # Skip self-check\n",
    "\n",
    "            # Check if P2P access is possible\n",
    "            try:\n",
    "                # Enable P2P access (temporarily)\n",
    "                torch.cuda.set_device(i)  # Set current GPU\n",
    "                can_access = torch.cuda.can_device_access_peer(i,j)\n",
    "                print(f\"GPU {i} can access GPU {j} via P2P: {'✅ Yes' if can_access else '❌ No'}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"P2P between GPU {i} and GPU {j} not supported: {e}\")\n",
    "\n",
    "check_p2p_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c76d9",
   "metadata": {},
   "source": [
    "## Pybind Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc4ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_utils_pybind import get_ipc_handle_pybind, tensor_restore_from_handler_pybind,merge_tensors_and_export_ipc_handle\n",
    "import torch\n",
    "token_num = 4096\n",
    "\n",
    "def get_dtype_size(dtype):\n",
    "    \"\"\"获取dtype的字节大小\"\"\"\n",
    "    return torch.tensor([], dtype=dtype).element_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdae1a",
   "metadata": {},
   "source": [
    "## handler preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488852eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_num = 1024\n",
    "hidden_states = torch.randn( token_num, 2048, dtype=torch.float32).to(\"cuda\")\n",
    "topk_ids = torch.randint(0, 60, (token_num, 4), dtype=torch.int32).to(\"cuda\")\n",
    "topk_weights = torch.randn(token_num, 4, dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "tensors=[hidden_states,topk_weights,topk_ids]\n",
    "\n",
    "handler = merge_tensors_and_export_ipc_handle(tensors,hidden_states[0].device.index)\n",
    "torch.cuda.synchronize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89f3ae",
   "metadata": {},
   "source": [
    "## metadata preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13414b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_dtype: torch.float32, max_dtype_size: 4 \n",
      "total_elements: 2103296\n"
     ]
    }
   ],
   "source": [
    "max_dtype = max(tensors, key=lambda t: get_dtype_size(t.dtype)).dtype\n",
    "max_dtype_size = get_dtype_size(max_dtype)\n",
    "print(f\"max_dtype: {max_dtype}, max_dtype_size: {max_dtype_size} \")\n",
    "\n",
    "# 2. 计算总元素数（考虑对齐）\n",
    "total_elements = 0\n",
    "metadata = []\n",
    "offset_bytes = 0\n",
    "for tensor in tensors:\n",
    "    # 计算当前张量需要的元素数（考虑对齐）\n",
    "    tensor_bytes = tensor.numel() * get_dtype_size(tensor.dtype)\n",
    "    elements_needed = (tensor_bytes + max_dtype_size - 1) // max_dtype_size\n",
    "    \n",
    "    # 记录元数据\n",
    "    metadata.append({\n",
    "        'dtype': str(tensor.dtype),\n",
    "        'shape': tensor.shape,\n",
    "        'device': tensor.device.index,\n",
    "        'offset_bytes':offset_bytes\n",
    "    })\n",
    "    offset_bytes += tensor_bytes\n",
    "    total_elements += elements_needed\n",
    "print(f\"total_elements: {total_elements}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf47823",
   "metadata": {},
   "source": [
    "## Send requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f73b42f",
   "metadata": {},
   "source": [
    "### Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3805ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors: [tensor([[-0.4055, -0.5077,  1.3535,  ..., -0.4322, -0.6301, -0.6791],\n",
      "        [-0.2482, -0.2057, -0.9148,  ..., -0.4003, -1.0719,  0.2630],\n",
      "        [ 1.6116,  1.6385,  0.9094,  ...,  0.5347, -0.6238, -0.7083],\n",
      "        ...,\n",
      "        [ 0.5343, -0.9832,  0.9822,  ...,  0.7232, -0.1213, -1.6530],\n",
      "        [-0.1056,  0.0625,  0.4504,  ...,  0.2294, -2.3053,  1.1465],\n",
      "        [ 0.0213, -0.1226, -2.0355,  ...,  0.0794,  1.3142,  0.7398]],\n",
      "       device='cuda:1'), tensor([[ 0.0153,  0.2168,  0.3789,  0.7266],\n",
      "        [ 0.2334, -1.7578,  1.6328,  0.0918],\n",
      "        [-0.1523, -0.1279,  0.9219, -0.4004],\n",
      "        ...,\n",
      "        [-1.4062, -0.1504,  0.1631, -0.4902],\n",
      "        [-0.8867, -0.3945, -0.1816, -1.1797],\n",
      "        [ 0.5547,  1.2031,  0.9336,  0.1338]], device='cuda:1',\n",
      "       dtype=torch.bfloat16), tensor([[45, 40, 47, 27],\n",
      "        [24, 41, 45, 17],\n",
      "        [16,  6, 25, 13],\n",
      "        ...,\n",
      "        [17, 48,  8,  2],\n",
      "        [17, 10, 23, 56],\n",
      "        [38, 19, 14,  1]], device='cuda:1', dtype=torch.int32)]\n",
      "metadata: [{'dtype': 'torch.float32', 'shape': torch.Size([1024, 2048]), 'device': 1, 'offset_bytes': 0}, {'dtype': 'torch.bfloat16', 'shape': torch.Size([1024, 4]), 'device': 1, 'offset_bytes': 8388608}, {'dtype': 'torch.int32', 'shape': torch.Size([1024, 4]), 'device': 1, 'offset_bytes': 8396800}]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensors: {tensors}\")\n",
    "print(f\"metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5becb",
   "metadata": {},
   "source": [
    "### Sending requests and in the server side restore multiple tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb08428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "url1 = \"http://localhost:1177/merged_handler\"\n",
    "\n",
    "#2101248\n",
    "\n",
    "response1 = requests.post(url1, \n",
    "  data={\n",
    "        'hidden_states_meta': json.dumps(metadata[0]),\n",
    "        'topk_weights_meta': json.dumps(metadata[1]),\n",
    "        'topk_ids_meta': json.dumps(metadata[2]),\n",
    "},\n",
    "                          \n",
    "files={\n",
    "        'handler': ('handler.bin', handler, 'application/octet-stream'),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fb5d8",
   "metadata": {},
   "source": [
    "### Sending requests and in the server side restore 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221d2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# md={'dtype': 'torch.float32',\n",
    "#  'shape': [1024*2048+4096],\n",
    "#  'offset': 0,\n",
    "#  'elements': 1024*2048+4096,\n",
    "#  'device': 1,\n",
    "#  'offset_bytes': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a479659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import requests\n",
    "# url1 = \"http://localhost:1177/merged_single\"\n",
    "\n",
    "# #2101248\n",
    "\n",
    "# response1 = requests.post(url1, \n",
    "#   data={\n",
    "#         'hidden_states_meta': json.dumps(md),\n",
    "#         # 'topk_ids_meta': json.dumps(metadata[2]),\n",
    "# },\n",
    "                          \n",
    "# files={\n",
    "#         'merged_handler': ('merged_handler.bin', merged_handler, 'application/octet-stream'),\n",
    "# })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
